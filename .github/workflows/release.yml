name: Release

on:
  workflow_dispatch:
  push:
    tags:
      - "v*"

jobs:
#  pypi:
#    name: Publish release artifact on PyPi repository
#    runs-on: ubuntu-latest
#    steps:
#      - name: Set up Python
#        uses: actions/setup-python@v4
#        with:
#          python-version: 3.10
#
#      - name: Check out the repo
#        uses: actions/checkout@v4
#
#      - name: Install dependencies
#        run: |
#          pip install --upgrade pip
#          pip install setuptools wheel
#
#      - run: |
#          python setup.py sdist bdist_wheel
#      - run: |
#          pip install twine
#
#      - name: Upload to PyPi
#        env:
#          OPTIMUM_NVIDIA_PYPI_TOKEN: ${{ secrets.OPTIMUM_NVIDIA_PYPI_TOKEN }}
#        run: |
#          twine upload dist/* -u __token__ -p "$OPTIMUM_NVIDIA_PYPI_TOKEN"

  docker:
    name: Build and push containers to registries
    runs-on:
      group: aws-highmemory-32-plus
    permissions:
      contents: read
      attestations: write
      id-token: write
    strategy:
      matrix:
        python-version: ['3.10', '3.12']

    steps:
      - name: Extract inlined Python version
        run: echo "INLINE_PYTHON_VERSION=$(echo ${{ matrix.python-version }} | sed 's/\.//')" >> $GITHUB_ENV

      - name: Check out the repo
        uses: actions/checkout@v4

      - name: Retrieve TensorRT-LLM dependency
        run:  echo "TENSORRT_LLM_VERSION=$(grep -i 'tensorrt-llm ==' setup.py | cut -c22- | rev | cut -c3- | rev)" >> $GITHUB_ENV

      - name: Print out targeted TensorRT-LLM version
        run: echo "Building against TensorRT-LLM ${{ env.TENSORRT_LLM_VERSION }}"

      - name: Make sure Git-LFS is installed
        run: |
          apt update
          apt install -y git-lfs
          git lfs install

      - name: Check out TensorRT-LLM repo
        uses: actions/checkout@v4
        with:
          path: tensorrt-llm
          repository: nvidia/tensorrt-llm
          submodules: true
          lfs: true
          fetch-depth: 1
          ref: v${{ env.TENSORRT_LLM_VERSION }}

      - name: Build TensorRT-LLM base image
        id: build-tensorrt-llm-base
        run: |
          cd tensorrt-llm
          make -C docker release_build \
            IMAGE_TAG=v${{ env.TENSORRT_LLM_VERSION}}-py${{ matrix.python-version }} \
            CUDA_ARCHS="75-real;80-real;86-real;89-real;90-real" \
            PYTHON_VERSION=${{ matrix.python-version }}

      - name: Check out the repo
        uses: actions/checkout@v4

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      - name: Extract metadata (tags, labels) for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: huggingface/optimum-nvidia
          tags: |
            type=pep440,pattern={{raw}},suffix=-py${{ env.INLINE_PYTHON_VERSION }}
            type=semver,pattern={{raw}},suffix=-py${{ env.INLINE_PYTHON_VERSION }}

      - name: Build and push Docker image
        id: push
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}


      - name: Generate artifact attestation
        uses: actions/attest-build-provenance@v2
        with:
          subject-name: huggingface/optimum-nvidia
          subject-digest: ${{ steps.push.outputs.digest }}
          push-to-registry: true